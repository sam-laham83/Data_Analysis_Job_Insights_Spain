{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee MÃ©xico</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>melalui Trabajo.org</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023-03-13 06:16:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAREERSTAR INTERNATIONAL PTE. LTD.</td>\n",
       "      <td>['bash', 'python', 'perl', 'linux', 'unix', 'k...</td>\n",
       "      <td>{'os': ['linux', 'unix'], 'other': ['kubernete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Commercial Analyst - Start Now</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>melalui Ricebowl</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2023-03-12 06:32:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lendlease Corporation</td>\n",
       "      <td>['powerpoint', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['powerpoint', 'excel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Principal Associate, Data Engineer (Remote-Eli...</td>\n",
       "      <td>Newark, New Jersey, Amerika Serikat</td>\n",
       "      <td>melalui Recruit.net</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-03-12 06:32:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>['python', 'go', 'nosql', 'sql', 'mongo', 'she...</td>\n",
       "      <td>{'cloud': ['aws', 'snowflake', 'azure', 'redsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>AWS System Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Trigyn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigyn</td>\n",
       "      <td>['aws', 'flow']</td>\n",
       "      <td>{'cloud': ['aws'], 'other': ['flow']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785741 rows Ã 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title_short  \\\n",
       "0       Senior Data Engineer   \n",
       "1               Data Analyst   \n",
       "2              Data Engineer   \n",
       "3              Data Engineer   \n",
       "4              Data Engineer   \n",
       "...                      ...   \n",
       "785736     Software Engineer   \n",
       "785737          Data Analyst   \n",
       "785738      Business Analyst   \n",
       "785739         Data Engineer   \n",
       "785740     Software Engineer   \n",
       "\n",
       "                                                job_title  \\\n",
       "0       Senior Clinical Data Engineer / Principal Clin...   \n",
       "1                                            Data Analyst   \n",
       "2       Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3       LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4                                  Data Engineer- Sr Jobs   \n",
       "...                                                   ...   \n",
       "785736                                    DevOps Engineer   \n",
       "785737                                   CRM Data Analyst   \n",
       "785738                     Commercial Analyst - Start Now   \n",
       "785739  Principal Associate, Data Engineer (Remote-Eli...   \n",
       "785740                                 AWS System Analyst   \n",
       "\n",
       "                               job_location                    job_via  \\\n",
       "0                             Watertown, CT            via Work Nearby   \n",
       "1              Guadalajara, Jalisco, Mexico           via BeBee MÃ©xico   \n",
       "2                           Berlin, Germany               via LinkedIn   \n",
       "3                           San Antonio, TX          via Diversity.com   \n",
       "4                            Washington, DC         via Clearance Jobs   \n",
       "...                                     ...                        ...   \n",
       "785736                            Singapura        melalui Trabajo.org   \n",
       "785737                   Bad Rodach, Jerman  melalui BeBee Deutschland   \n",
       "785738                             Malaysia           melalui Ricebowl   \n",
       "785739  Newark, New Jersey, Amerika Serikat        melalui Recruit.net   \n",
       "785740                                India             melalui Trigyn   \n",
       "\n",
       "       job_schedule_type  job_work_from_home       search_location  \\\n",
       "0              Full-time               False  Texas, United States   \n",
       "1              Full-time               False                Mexico   \n",
       "2              Full-time               False               Germany   \n",
       "3              Full-time               False  Texas, United States   \n",
       "4              Full-time               False                 Sudan   \n",
       "...                  ...                 ...                   ...   \n",
       "785736   Pekerjaan tetap               False             Singapore   \n",
       "785737   Pekerjaan tetap               False               Germany   \n",
       "785738   Pekerjaan tetap               False              Malaysia   \n",
       "785739   Pekerjaan tetap               False                 Sudan   \n",
       "785740   Pekerjaan tetap               False                 India   \n",
       "\n",
       "           job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "0      2023-06-16 13:44:15                  False                 False   \n",
       "1      2023-01-14 13:18:07                  False                 False   \n",
       "2      2023-10-10 13:14:55                  False                 False   \n",
       "3      2023-07-04 13:01:41                   True                 False   \n",
       "4      2023-08-07 14:29:36                  False                 False   \n",
       "...                    ...                    ...                   ...   \n",
       "785736 2023-03-13 06:16:16                  False                 False   \n",
       "785737 2023-03-12 06:18:18                  False                 False   \n",
       "785738 2023-03-12 06:32:36                  False                 False   \n",
       "785739 2023-03-12 06:32:15                  False                 False   \n",
       "785740 2023-03-13 06:16:31                  False                 False   \n",
       "\n",
       "          job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0       United States        None              NaN              NaN   \n",
       "1              Mexico        None              NaN              NaN   \n",
       "2             Germany        None              NaN              NaN   \n",
       "3       United States        None              NaN              NaN   \n",
       "4               Sudan        None              NaN              NaN   \n",
       "...               ...         ...              ...              ...   \n",
       "785736      Singapore        None              NaN              NaN   \n",
       "785737        Germany        None              NaN              NaN   \n",
       "785738       Malaysia        None              NaN              NaN   \n",
       "785739          Sudan        None              NaN              NaN   \n",
       "785740          India        None              NaN              NaN   \n",
       "\n",
       "                              company_name  \\\n",
       "0                     Boehringer Ingelheim   \n",
       "1               Hewlett Packard Enterprise   \n",
       "2                 ALPHA Augmented Services   \n",
       "3             Southwest Research Institute   \n",
       "4                          Kristina Daniel   \n",
       "...                                    ...   \n",
       "785736  CAREERSTAR INTERNATIONAL PTE. LTD.   \n",
       "785737                    HABA FAMILYGROUP   \n",
       "785738               Lendlease Corporation   \n",
       "785739                         Capital One   \n",
       "785740                              Trigyn   \n",
       "\n",
       "                                               job_skills  \\\n",
       "0                                                    None   \n",
       "1       ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2       ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3       ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4       ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "...                                                   ...   \n",
       "785736  ['bash', 'python', 'perl', 'linux', 'unix', 'k...   \n",
       "785737                     ['sas', 'sas', 'sql', 'excel']   \n",
       "785738                            ['powerpoint', 'excel']   \n",
       "785739  ['python', 'go', 'nosql', 'sql', 'mongo', 'she...   \n",
       "785740                                    ['aws', 'flow']   \n",
       "\n",
       "                                          job_type_skills  \n",
       "0                                                    None  \n",
       "1       {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2       {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3       {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4       {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "...                                                   ...  \n",
       "785736  {'os': ['linux', 'unix'], 'other': ['kubernete...  \n",
       "785737  {'analyst_tools': ['sas', 'excel'], 'programmi...  \n",
       "785738         {'analyst_tools': ['powerpoint', 'excel']}  \n",
       "785739  {'cloud': ['aws', 'snowflake', 'azure', 'redsh...  \n",
       "785740              {'cloud': ['aws'], 'other': ['flow']}  \n",
       "\n",
       "[785741 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset('csv', data_files=r'C:\\Users\\sami.laham\\Documents\\Sam\\Data Analysis Training\\Luke Barousse\\CSV files\\data_jobs.csv')\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleaning: Convert the 'job_posted_date' to datetime\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])\n",
    "\n",
    "# Show the first few rows of the DataFrame to check the results\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28        109500.0\n",
       "77        140000.0\n",
       "92        120000.0\n",
       "100       228222.0\n",
       "109        89000.0\n",
       "            ...   \n",
       "785624    139216.0\n",
       "785641    150000.0\n",
       "785648    221875.0\n",
       "785682    157500.0\n",
       "785692    157500.0\n",
       "Name: salary_year_avg, Length: 22003, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.notna(df['salary_year_avg'])]['salary_year_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method apply in module pandas.core.frame:\n",
      "\n",
      "apply(func: 'AggFuncType', axis: 'Axis' = 0, raw: 'bool' = False, result_type: \"Literal['expand', 'reduce', 'broadcast'] | None\" = None, args=(), by_row: \"Literal[False, 'compat']\" = 'compat', engine: \"Literal['python', 'numba']\" = 'python', engine_kwargs: 'dict[str, bool] | None' = None, **kwargs) method of pandas.core.frame.DataFrame instance\n",
      "    Apply a function along an axis of the DataFrame.\n",
      "\n",
      "    Objects passed to the function are Series objects whose index is\n",
      "    either the DataFrame's index (``axis=0``) or the DataFrame's columns\n",
      "    (``axis=1``). By default (``result_type=None``), the final return type\n",
      "    is inferred from the return type of the applied function. Otherwise,\n",
      "    it depends on the `result_type` argument.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function\n",
      "        Function to apply to each column or row.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Axis along which the function is applied:\n",
      "\n",
      "        * 0 or 'index': apply function to each column.\n",
      "        * 1 or 'columns': apply function to each row.\n",
      "\n",
      "    raw : bool, default False\n",
      "        Determines if row or column is passed as a Series or ndarray object:\n",
      "\n",
      "        * ``False`` : passes each row or column as a Series to the\n",
      "          function.\n",
      "        * ``True`` : the passed function will receive ndarray objects\n",
      "          instead.\n",
      "          If you are just applying a NumPy reduction function this will\n",
      "          achieve much better performance.\n",
      "\n",
      "    result_type : {'expand', 'reduce', 'broadcast', None}, default None\n",
      "        These only act when ``axis=1`` (columns):\n",
      "\n",
      "        * 'expand' : list-like results will be turned into columns.\n",
      "        * 'reduce' : returns a Series if possible rather than expanding\n",
      "          list-like results. This is the opposite of 'expand'.\n",
      "        * 'broadcast' : results will be broadcast to the original shape\n",
      "          of the DataFrame, the original index and columns will be\n",
      "          retained.\n",
      "\n",
      "        The default behaviour (None) depends on the return value of the\n",
      "        applied function: list-like results will be returned as a Series\n",
      "        of those. However if the apply function returns a Series these\n",
      "        are expanded to columns.\n",
      "    args : tuple\n",
      "        Positional arguments to pass to `func` in addition to the\n",
      "        array/series.\n",
      "    by_row : False or \"compat\", default \"compat\"\n",
      "        Only has an effect when ``func`` is a listlike or dictlike of funcs\n",
      "        and the func isn't a string.\n",
      "        If \"compat\", will if possible first translate the func into pandas\n",
      "        methods (e.g. ``Series().apply(np.sum)`` will be translated to\n",
      "        ``Series().sum()``). If that doesn't work, will try call to apply again with\n",
      "        ``by_row=True`` and if that fails, will call apply again with\n",
      "        ``by_row=False`` (backward compatible).\n",
      "        If False, the funcs will be passed the whole Series at once.\n",
      "\n",
      "        .. versionadded:: 2.1.0\n",
      "\n",
      "    engine : {'python', 'numba'}, default 'python'\n",
      "        Choose between the python (default) engine or the numba engine in apply.\n",
      "\n",
      "        The numba engine will attempt to JIT compile the passed function,\n",
      "        which may result in speedups for large DataFrames.\n",
      "        It also supports the following engine_kwargs :\n",
      "\n",
      "        - nopython (compile the function in nopython mode)\n",
      "        - nogil (release the GIL inside the JIT compiled function)\n",
      "        - parallel (try to apply the function in parallel over the DataFrame)\n",
      "\n",
      "          Note: Due to limitations within numba/how pandas interfaces with numba,\n",
      "          you should only use this if raw=True\n",
      "\n",
      "        Note: The numba compiler only supports a subset of\n",
      "        valid Python/numpy operations.\n",
      "\n",
      "        Please read more about the `supported python features\n",
      "        <https://numba.pydata.org/numba-doc/dev/reference/pysupported.html>`_\n",
      "        and `supported numpy features\n",
      "        <https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html>`_\n",
      "        in numba to learn what you can or cannot use in the passed function.\n",
      "\n",
      "        .. versionadded:: 2.2.0\n",
      "\n",
      "    engine_kwargs : dict\n",
      "        Pass keyword arguments to the engine.\n",
      "        This is currently only used by the numba engine,\n",
      "        see the documentation for the engine argument for more information.\n",
      "    **kwargs\n",
      "        Additional keyword arguments to pass as keywords arguments to\n",
      "        `func`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    Series or DataFrame\n",
      "        Result of applying ``func`` along the given axis of the\n",
      "        DataFrame.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.map: For elementwise operations.\n",
      "    DataFrame.aggregate: Only perform aggregating type operations.\n",
      "    DataFrame.transform: Only perform transforming type operations.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Functions that mutate the passed object can produce unexpected\n",
      "    behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      "    for more details.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
      "    >>> df\n",
      "       A  B\n",
      "    0  4  9\n",
      "    1  4  9\n",
      "    2  4  9\n",
      "\n",
      "    Using a numpy universal function (in this case the same as\n",
      "    ``np.sqrt(df)``):\n",
      "\n",
      "    >>> df.apply(np.sqrt)\n",
      "         A    B\n",
      "    0  2.0  3.0\n",
      "    1  2.0  3.0\n",
      "    2  2.0  3.0\n",
      "\n",
      "    Using a reducing function on either axis\n",
      "\n",
      "    >>> df.apply(np.sum, axis=0)\n",
      "    A    12\n",
      "    B    27\n",
      "    dtype: int64\n",
      "\n",
      "    >>> df.apply(np.sum, axis=1)\n",
      "    0    13\n",
      "    1    13\n",
      "    2    13\n",
      "    dtype: int64\n",
      "\n",
      "    Returning a list-like will result in a Series\n",
      "\n",
      "    >>> df.apply(lambda x: [1, 2], axis=1)\n",
      "    0    [1, 2]\n",
      "    1    [1, 2]\n",
      "    2    [1, 2]\n",
      "    dtype: object\n",
      "\n",
      "    Passing ``result_type='expand'`` will expand list-like results\n",
      "    to columns of a Dataframe\n",
      "\n",
      "    >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\n",
      "       0  1\n",
      "    0  1  2\n",
      "    1  1  2\n",
      "    2  1  2\n",
      "\n",
      "    Returning a Series inside the function is similar to passing\n",
      "    ``result_type='expand'``. The resulting column names\n",
      "    will be the Series index.\n",
      "\n",
      "    >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\n",
      "       foo  bar\n",
      "    0    1    2\n",
      "    1    1    2\n",
      "    2    1    2\n",
      "\n",
      "    Passing ``result_type='broadcast'`` will ensure the same shape\n",
      "    result, whether list-like or scalar is returned by the function,\n",
      "    and broadcast it along the axis. The resulting column names will\n",
      "    be the originals.\n",
      "\n",
      "    >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  1  2\n",
      "    2  1  2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['salary_year_inflated'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m salary \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.03\u001b[39m\n\u001b[0;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary_year_inflated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_salary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary_year_avg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(projected_salary)\n\u001b[1;32m----> 7\u001b[0m df_salary[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary_year_avg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary_year_inflated\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['salary_year_inflated'] not in index\""
     ]
    }
   ],
   "source": [
    "df_salary = df[pd.notna(df['salary_year_avg'])]\n",
    "\n",
    "def projected_salary(salary):\n",
    "    return salary * 1.03\n",
    "\n",
    "df['salary_year_inflated'] = df_salary['salary_year_avg'].apply(projected_salary)\n",
    "df_salary[['salary_year_avg', 'salary_year_inflated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sami.laham\\AppData\\Local\\Temp\\ipykernel_19708\\1418313773.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_salary['salary_year_inflated'] = df_salary ['salary_year_avg'].apply(lambda salary: salary * 1.03)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_year_inflated\n",
       "28             109500.0             112785.00\n",
       "77             140000.0             144200.00\n",
       "92             120000.0             123600.00\n",
       "100            228222.0             235068.66\n",
       "109             89000.0              91670.00\n",
       "...                 ...                   ...\n",
       "785624         139216.0             143392.48\n",
       "785641         150000.0             154500.00\n",
       "785648         221875.0             228531.25\n",
       "785682         157500.0             162225.00\n",
       "785692         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary['salary_year_inflated'] = df_salary ['salary_year_avg'].apply(lambda salary: salary * 1.03)\n",
    "\n",
    "df_salary[['salary_year_avg', 'salary_year_inflated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ast\u001b[38;5;241m.\u001b[39mliteral_eval(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_skills\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\ast.py:112\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\ast.py:111\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\ast.py:85\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\ast.py:76\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[1;32m---> 76\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\ast.py:73\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     72\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval(df['job_skills'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ast.literal_eval(df['job_skills'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Stage - data scientist â gÃ©nÃ©ration ia de donn...</td>\n",
       "      <td>AsniÃ¨res-sur-Seine, France</td>\n",
       "      <td>via Jobijoba</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>France</td>\n",
       "      <td>2023-02-23 13:41:21</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>France</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Credit Agricole</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>United States</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>2023-09-15 13:56:18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Infinite Computer Solutions</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pune, Maharashtra, India</td>\n",
       "      <td>via Exusia</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-26 13:16:20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exusia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Des Moines, IA</td>\n",
       "      <td>via Trabajo.org</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Illinois, United States</td>\n",
       "      <td>2023-11-06 13:01:22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assuredpartners</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785713</th>\n",
       "      <td>Cloud Engineer</td>\n",
       "      <td>Data Center Chief Engineer, AWS Infrastructure...</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>melalui LinkedIn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>2023-03-12 06:37:47</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785715</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Amul Careers 2023 - Apply Online - Data Analys...</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Jobsleworld - Jobs In India - Job Vaca...</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amul</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785718</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Senior Performance QA Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui BeBee India</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diebold Nixdorf</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785724</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Junior Consultant Data Engineering</td>\n",
       "      <td>Koln, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-13 06:19:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Target Reply</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785729</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer Marketing Intelligence</td>\n",
       "      <td>Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IU Internationale Hochschule</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117037 rows Ã 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title_short  \\\n",
       "0       Senior Data Engineer   \n",
       "21            Data Scientist   \n",
       "26             Data Engineer   \n",
       "29            Data Scientist   \n",
       "36              Data Analyst   \n",
       "...                      ...   \n",
       "785713        Cloud Engineer   \n",
       "785715          Data Analyst   \n",
       "785718      Business Analyst   \n",
       "785724         Data Engineer   \n",
       "785729         Data Engineer   \n",
       "\n",
       "                                                job_title  \\\n",
       "0       Senior Clinical Data Engineer / Principal Clin...   \n",
       "21      Stage - data scientist â gÃ©nÃ©ration ia de donn...   \n",
       "26                                          Data Engineer   \n",
       "29                                         Data Scientist   \n",
       "36                                           Data Analyst   \n",
       "...                                                   ...   \n",
       "785713  Data Center Chief Engineer, AWS Infrastructure...   \n",
       "785715  Amul Careers 2023 - Apply Online - Data Analys...   \n",
       "785718                      Senior Performance QA Analyst   \n",
       "785724                 Junior Consultant Data Engineering   \n",
       "785729               Data Engineer Marketing Intelligence   \n",
       "\n",
       "                      job_location  \\\n",
       "0                    Watertown, CT   \n",
       "21      AsniÃ¨res-sur-Seine, France   \n",
       "26                   United States   \n",
       "29        Pune, Maharashtra, India   \n",
       "36                  Des Moines, IA   \n",
       "...                            ...   \n",
       "785713           Bangkok, Thailand   \n",
       "785715                       India   \n",
       "785718                       India   \n",
       "785724                Koln, Jerman   \n",
       "785729                      Jerman   \n",
       "\n",
       "                                                  job_via job_schedule_type  \\\n",
       "0                                         via Work Nearby         Full-time   \n",
       "21                                           via Jobijoba         Full-time   \n",
       "26                                           via LinkedIn         Full-time   \n",
       "29                                             via Exusia         Full-time   \n",
       "36                                        via Trabajo.org         Full-time   \n",
       "...                                                   ...               ...   \n",
       "785713                                   melalui LinkedIn   Pekerjaan tetap   \n",
       "785715  melalui Jobsleworld - Jobs In India - Job Vaca...   Pekerjaan tetap   \n",
       "785718                                melalui BeBee India   Pekerjaan tetap   \n",
       "785724                          melalui BeBee Deutschland   Pekerjaan tetap   \n",
       "785729                          melalui BeBee Deutschland   Pekerjaan tetap   \n",
       "\n",
       "        job_work_from_home          search_location     job_posted_date  \\\n",
       "0                    False     Texas, United States 2023-06-16 13:44:15   \n",
       "21                   False                   France 2023-02-23 13:41:21   \n",
       "26                   False                  Georgia 2023-09-15 13:56:18   \n",
       "29                   False                    India 2023-03-26 13:16:20   \n",
       "36                   False  Illinois, United States 2023-11-06 13:01:22   \n",
       "...                    ...                      ...                 ...   \n",
       "785713               False                 Thailand 2023-03-12 06:37:47   \n",
       "785715               False                    India 2023-03-13 06:16:28   \n",
       "785718               False                    India 2023-03-13 06:16:28   \n",
       "785724               False                  Germany 2023-03-13 06:19:07   \n",
       "785729               False                  Germany 2023-03-12 06:18:18   \n",
       "\n",
       "        job_no_degree_mention  job_health_insurance    job_country  \\\n",
       "0                       False                 False  United States   \n",
       "21                      False                 False         France   \n",
       "26                       True                 False  United States   \n",
       "29                      False                 False          India   \n",
       "36                      False                  True  United States   \n",
       "...                       ...                   ...            ...   \n",
       "785713                  False                 False       Thailand   \n",
       "785715                  False                 False          India   \n",
       "785718                  False                 False          India   \n",
       "785724                  False                 False        Germany   \n",
       "785729                  False                 False        Germany   \n",
       "\n",
       "       salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0             None              NaN              NaN   \n",
       "21            None              NaN              NaN   \n",
       "26            None              NaN              NaN   \n",
       "29            None              NaN              NaN   \n",
       "36            None              NaN              NaN   \n",
       "...            ...              ...              ...   \n",
       "785713        None              NaN              NaN   \n",
       "785715        None              NaN              NaN   \n",
       "785718        None              NaN              NaN   \n",
       "785724        None              NaN              NaN   \n",
       "785729        None              NaN              NaN   \n",
       "\n",
       "                        company_name job_skills job_type_skills  \\\n",
       "0               Boehringer Ingelheim       None            None   \n",
       "21                   Credit Agricole       None            None   \n",
       "26       Infinite Computer Solutions       None            None   \n",
       "29                            Exusia       None            None   \n",
       "36                   Assuredpartners       None            None   \n",
       "...                              ...        ...             ...   \n",
       "785713     Amazon Web Services (AWS)       None            None   \n",
       "785715                          Amul       None            None   \n",
       "785718               Diebold Nixdorf       None            None   \n",
       "785724                  Target Reply       None            None   \n",
       "785729  IU Internationale Hochschule       None            None   \n",
       "\n",
       "        salary_year_inflated  \n",
       "0                        NaN  \n",
       "21                       NaN  \n",
       "26                       NaN  \n",
       "29                       NaN  \n",
       "36                       NaN  \n",
       "...                      ...  \n",
       "785713                   NaN  \n",
       "785715                   NaN  \n",
       "785718                   NaN  \n",
       "785724                   NaN  \n",
       "785729                   NaN  \n",
       "\n",
       "[117037 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pd.isna(df['job_skills'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(skill_list):\n",
    "    if pd.notna(skill_list):\n",
    "        return ast.literal_eval(skill_list)\n",
    "\n",
    "df['job_skills'] = df ['job_skills'].apply(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'sql',\n",
       " 'c#',\n",
       " 'azure',\n",
       " 'airflow',\n",
       " 'dax',\n",
       " 'docker',\n",
       " 'kubernetes',\n",
       " 'jenkins']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_skills'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_skills\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_skills\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m skill_list: ast\u001b[38;5;241m.\u001b[39mliteral_eval(skill_list) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(skill_list) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\sami.laham\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(skill_list)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_skills\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_skills\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m skill_list: ast\u001b[38;5;241m.\u001b[39mliteral_eval(skill_list) \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(skill_list) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "df['job_skills'] = df['job_skills'].apply(lambda skill_list: ast.literal_eval(skill_list) if pd.notna(skill_list) else skill_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python',\n",
       " 'sql',\n",
       " 'c#',\n",
       " 'azure',\n",
       " 'airflow',\n",
       " 'dax',\n",
       " 'docker',\n",
       " 'kubernetes',\n",
       " 'jenkins']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_skills'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sami.laham\\AppData\\Local\\Temp\\ipykernel_10984\\3323245091.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_salary['salary_year_inflated'] = df_salary ['salary_year_avg'].apply (lambda salary: salary * 1.03)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_year_inflated\n",
       "28             109500.0             112785.00\n",
       "77             140000.0             144200.00\n",
       "92             120000.0             123600.00\n",
       "100            228222.0             235068.66\n",
       "109             89000.0              91670.00\n",
       "...                 ...                   ...\n",
       "785624         139216.0             143392.48\n",
       "785641         150000.0             154500.00\n",
       "785648         221875.0             228531.25\n",
       "785682         157500.0             162225.00\n",
       "785692         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_salary['salary_year_inflated'] = df_salary ['salary_year_avg'].apply (lambda salary: salary * 1.03)\n",
    "df_salary[['salary_year_avg', 'salary_year_inflated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sami.laham\\AppData\\Local\\Temp\\ipykernel_10984\\23795078.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_salary['salary_year_inflated'] = df_salary.apply (projected_salary, axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_year_inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>109500.0</td>\n",
       "      <td>112785.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>144200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>123600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>228222.0</td>\n",
       "      <td>235068.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>91670.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785624</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>139216.0</td>\n",
       "      <td>143392.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>154500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785648</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>221875.0</td>\n",
       "      <td>228531.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785682</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785692</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>162225.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22003 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_title_short  salary_year_avg  salary_year_inflated\n",
       "28      Data Scientist         109500.0             112785.00\n",
       "77       Data Engineer         140000.0             144200.00\n",
       "92       Data Engineer         120000.0             123600.00\n",
       "100     Data Scientist         228222.0             235068.66\n",
       "109       Data Analyst          89000.0              91670.00\n",
       "...                ...              ...                   ...\n",
       "785624   Data Engineer         139216.0             143392.48\n",
       "785641   Data Engineer         150000.0             154500.00\n",
       "785648  Data Scientist         221875.0             228531.25\n",
       "785682  Data Scientist         157500.0             162225.00\n",
       "785692  Data Scientist         157500.0             162225.00\n",
       "\n",
       "[22003 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def projected_salary(row):\n",
    "    if \"Senior\" in row ['job_title_short']:\n",
    "        return 1.05 * row ['salary_year_avg']\n",
    "    else: \n",
    "        return 1.03 * row ['salary_year_avg']\n",
    "    \n",
    "df_salary['salary_year_inflated'] = df_salary.apply (projected_salary, axis = 1)\n",
    "df_salary [['job_title_short', 'salary_year_avg', 'salary_year_inflated']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sami.laham\\AppData\\Local\\Temp\\ipykernel_10984\\191243979.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_salary['salary_year_inflated'] = df_salary.apply(\n"
     ]
    }
   ],
   "source": [
    "df_salary['salary_year_inflated'] = df_salary.apply(\n",
    "    lambda row: 1.05 * row['salary_year_avg'] if \"Senior\" in row['job_title_short'] else 1.03 * row['salary_year_avg'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
